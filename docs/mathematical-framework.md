# Mathematical Framework

Detris provides a formal mathematical foundation for verifiable game-state computation, enabling rigorous proofs of correctness, determinism, and learning progress.

---

## Core Definitions

### State Space

**Definition 1 (Grid State):**
```
A grid G is a function G: ‚Ñ§‚ÇÅ‚ÇÄ √ó ‚Ñ§‚ÇÅ‚ÇÄ ‚Üí Œ£
where Œ£ = {‚†Ä, ‚†¥, ‚†¶, ‚†ß, ‚†á, ‚†è, ‚†ã, ‚†ô, ‚†π, ‚†∏, ‚†º} is the braille alphabet.
```

The state space is:
```
ùí¢ = Œ£^(10√ó10) = Œ£^100
|ùí¢| = 11^100 ‚âà 2.56 √ó 10^104 possible states
```

**Definition 2 (Occupancy):**
```
occupied(G, r, c) = (G(r, c) ‚â† ‚†Ä)
```

**Definition 3 (Row Fullness):**
```
full(G, r) = ‚àÄc ‚àà [0,9]: occupied(G, r, c)
```

---

## Game Dynamics

### Tetromino Shapes

The standard Tetris pieces in Detris:

**Definition 4 (Tetromino):**
```
A tetromino T is a set of relative coordinates:
T ‚äÜ {(Œîr, Œîc) : Œîr, Œîc ‚àà ‚Ñ§}
```

Standard pieces:

```
I-piece: {(0,0), (0,1), (0,2), (0,3)}
O-piece: {(0,0), (0,1), (1,0), (1,1)}
T-piece: {(0,0), (0,1), (0,2), (1,1)}
S-piece: {(0,1), (0,2), (1,0), (1,1)}
Z-piece: {(0,0), (0,1), (1,1), (1,2)}
J-piece: {(0,0), (1,0), (1,1), (1,2)}
L-piece: {(0,2), (1,0), (1,1), (1,2)}
```

### Rotations

**Definition 5 (Rotation Matrix):**
```
Clockwise 90¬∞:
R‚Çâ‚ÇÄ = [0  -1]
      [1   0]

Applied to coordinate (r, c):
R‚Çâ‚ÇÄ(r, c) = (-c, r)
```

**Definition 6 (Tetromino Rotation):**
```
rotate(T, Œ∏) = {RŒ∏(Œîr, Œîc) : (Œîr, Œîc) ‚àà T}
where Œ∏ ‚àà {0¬∞, 90¬∞, 180¬∞, 270¬∞}
```

### Collision Detection

**Definition 7 (Collision-Free Placement):**
```
valid(G, T, r‚ÇÄ, c‚ÇÄ) ‚ü∫ 
  ‚àÄ(Œîr, Œîc) ‚àà T:
    (r‚ÇÄ + Œîr) ‚àà [0, 9] ‚àß
    (c‚ÇÄ + Œîc) ‚àà [0, 9] ‚àß
    ¬¨occupied(G, r‚ÇÄ + Œîr, c‚ÇÄ + Œîc)
```

### State Transitions

**Definition 8 (Piece Placement):**
```
place(G, T, r‚ÇÄ, c‚ÇÄ, œÉ) = G'
where G'(r, c) = {
  œÉ,        if ‚àÉ(Œîr, Œîc) ‚àà T: (r, c) = (r‚ÇÄ + Œîr, c‚ÇÄ + Œîc)
  G(r, c),  otherwise
}
```

**Definition 9 (Line Clear):**
```
clear_row(G, r) = G' where:
  G'(r', c) = {
    G(r'-1, c),  if r' > r
    ‚†Ä,           if r' = r
    G(r', c),    if r' < r
  }
```

**Definition 10 (Gravity):**
```
apply_gravity(G) = G* where G* is the fixpoint of:
  ‚àÄr, c: occupied(G*, r+1, c) ‚à® ¬¨occupied(G*, r, c) ‚à® (r = 0)
```

---

## Deterministic Gameplay

### Move Sequence

**Definition 11 (Action):**
```
Action a ‚àà ùíú where:
ùíú = {left, right, down, rotate_cw, rotate_ccw, hard_drop}
```

**Definition 12 (Transition Function):**
```
Œ¥: ùí¢ √ó ùíú ‚Üí ùí¢ ‚à™ {‚ä•}
where ‚ä• represents invalid/terminal state
```

**Theorem 1 (Determinism):**
For any state G and action a, Œ¥(G, a) is uniquely determined.

*Proof:* Each action applies fixed rules (collision check, placement, clearing, gravity) with deterministic outcomes. ‚ñ°

### Trajectory

**Definition 13 (Game Trajectory):**
```
œÑ = (G‚ÇÄ, a‚ÇÅ, G‚ÇÅ, a‚ÇÇ, G‚ÇÇ, ..., a‚Çô, G‚Çô)
where G·µ¢ = Œ¥(G·µ¢‚Çã‚ÇÅ, a·µ¢) for all i ‚àà [1, n]
```

**Definition 14 (Valid Trajectory):**
```
valid(œÑ) ‚ü∫ ‚àÄi ‚àà [1, n]: G·µ¢ = Œ¥(G·µ¢‚Çã‚ÇÅ, a·µ¢) ‚àß G·µ¢ ‚â† ‚ä•
```

---

## Hash Commitments

### State Hashing

**Definition 15 (Canonical Serialization):**
```
serialize(G) = concat([G(r, c) for r ‚àà [9..0] for c ‚àà [0..9]])
Returns UTF-8 byte string of length 400 bytes (4 bytes per glyph)
```

**Definition 16 (State Hash):**
```
H(G) = SHA256(serialize(G))
Returns 256-bit digest
```

**Theorem 2 (Collision Resistance):**
For grids G‚ÇÅ ‚â† G‚ÇÇ, Pr[H(G‚ÇÅ) = H(G‚ÇÇ)] ‚âà 2‚Åª¬≤‚Åµ‚Å∂

*Proof:* Follows from SHA256 collision resistance. ‚ñ°

### Merkle Commitments

**Definition 17 (Row Hash):**
```
H_row(G, r) = SHA256(serialize_row(G, r))
where serialize_row(G, r) = concat([G(r, c) for c ‚àà [0..9]])
```

**Definition 18 (Merkle Root):**
```
MerkleRoot(G) = merkle_tree([H_row(G, r) for r ‚àà [0..9]])
```

This enables efficient proofs that a row is part of a grid without revealing the entire grid.

---

## Proof-of-Placement (PoP)

### PoP Structure

**Definition 19 (PoP Transcript):**
```
PoP = (h_prev, a, h_next, w)
where:
  h_prev = H(G_prev)    # Previous state hash
  a ‚àà ùíú                 # Action taken
  h_next = H(G_next)    # Resulting state hash
  w = witness           # Minimal validation data
```

**Definition 20 (Witness):**
```
w = (piece_type, position, rotation, cleared_rows)
```

### Verification

**Definition 21 (PoP Verification):**
```
verify_pop(PoP, G_prev) = {
  true,  if H(G_prev) = h_prev ‚àß 
            H(Œ¥(G_prev, a)) = h_next ‚àß
            witness_valid(w, G_prev, a)
  false, otherwise
}
```

**Theorem 3 (PoP Soundness):**
If verify_pop(PoP, G_prev) = true, then G_next was legally derived from G_prev via action a (with overwhelming probability).

*Proof:* Hash collision resistance ensures H(G_prev) uniquely identifies G_prev, and determinism ensures Œ¥(G_prev, a) is unique. ‚ñ°

---

## Proof-of-Learning (PoL)

### Challenge Distribution

**Definition 22 (Challenge):**
```
C = (seed, difficulty, constraints)
where:
  seed ‚àà ‚Ñï            # Random seed
  difficulty ‚àà [0,1]  # Task difficulty
  constraints: ùí¢ ‚Üí {0,1}  # Success predicate
```

**Definition 23 (Challenge Distribution):**
```
ùíü(seed) ‚Üí C
Deterministically generates challenge from seed
```

### Performance Metrics

**Definition 24 (Score Function):**
```
score(œÑ, C) = ‚àë·µ¢ reward(G·µ¢, a·µ¢, C)
where reward: ùí¢ √ó ùíú √ó Challenge ‚Üí ‚Ñù
```

**Example rewards:**
```
reward(G, a, C) = {
  +100,  if row cleared
  -1,    per move
  +1000, if constraints(G) holds
  -‚àû,    if game over
}
```

### Learning Progress

**Definition 25 (Learning Curve):**
```
LC(n) = ùîº[score(œÑ‚Çô, C‚Çô)]
where œÑ‚Çô is the agent's nth attempt
```

**Definition 26 (Improvement):**
```
Œî(n‚ÇÅ, n‚ÇÇ) = LC(n‚ÇÇ) - LC(n‚ÇÅ)
Measures score improvement from attempt n‚ÇÅ to n‚ÇÇ
```

**Theorem 4 (PoL Verification):**
Given PoP-valid trajectories {œÑ‚ÇÅ, ..., œÑ‚Çô}, the learning curve LC is verifiable by replaying all trajectories and computing scores.

*Proof:* PoP validity ensures each œÑ·µ¢ is legitimate, and score is a deterministic function of œÑ·µ¢ and C·µ¢. ‚ñ°

---

## Information Theory

### Entropy

**Definition 27 (State Entropy):**
```
H(G) = -‚àë_{r,c} p(G(r,c)) log‚ÇÇ p(G(r,c))
where p(œÉ) = Pr[G(r,c) = œÉ] over some distribution
```

**For uniform distribution:**
```
H_uniform = 100 √ó log‚ÇÇ(11) ‚âà 346 bits
```

**For typical game state (sparse):**
```
H_game ‚âà 50 bits (empirical)
```

### Mutual Information

**Definition 28 (Grid Mutual Information):**
```
I(G_A; G_B) = H(G_A) + H(G_B) - H(G_A, G_B)
```

Measures information shared between Grid A and Grid B in dual-plane architecture.

### Compression Bound

**Theorem 5 (Shannon's Source Coding):**
The expected code length L for encoding grids satisfies:
```
L ‚â• H(G)
```

Optimal codes achieve L = H(G).

*Proof:* Standard result from information theory. ‚ñ°

---

## Complexity Analysis

### State Space

**Theorem 6 (State Space Size):**
```
|ùí¢| = 11^100 ‚âà 2.56 √ó 10^104
```

This is larger than the estimated number of atoms in the observable universe (‚âà 10^80).

### Game Tree Complexity

**Definition 29 (Game Tree Depth):**
```
D = maximum moves before forced game over
D ‚âà 10,000 (empirical upper bound)
```

**Definition 30 (Branching Factor):**
```
b = average number of legal actions per state
b ‚âà 30-50 (empirical)
```

**Theorem 7 (Game Tree Complexity):**
```
|Tree| ‚â§ b^D ‚âà 50^10000 ‚âà 10^17000
```

### Computational Complexity

**Theorem 8 (Tetris Decision is NP-Complete):**
Determining whether a sequence of pieces can be cleared without exceeding height H is NP-complete.

*Reference:* Breukelaar et al., "Tetris is Hard, Even to Approximate" (2004)

---

## Probabilistic Analysis

### Random Piece Distribution

**Definition 31 (Uniform Piece Distribution):**
```
Pr[next_piece = T] = 1/7 for each tetromino type T
```

**Expected Lines per Piece:**
```
ùîº[lines_cleared | piece] ‚âà 0.5 (empirical)
```

### Survival Probability

**Definition 32 (Game Length Distribution):**
```
Pr[game_length ‚â• n] = p^n
where p ‚âà 0.95 (skilled play)
```

**Expected game length:**
```
ùîº[game_length] = 1/(1-p) ‚âà 20 (for random play)
ùîº[game_length] ‚âà 1000+ (for expert play)
```

---

## Cryptographic Properties

### Commitment Scheme

**Definition 33 (Grid Commitment):**
```
Commit(G, r) = (c, d)
where:
  c = H(G || r)  # Commitment (random salt r)
  d = (G, r)     # Decommitment
```

**Theorem 9 (Binding):**
Computationally infeasible to find (G, r) ‚â† (G', r') with H(G || r) = H(G' || r').

**Theorem 10 (Hiding):**
Given c = H(G || r) with random r, no information about G is revealed.

### Zero-Knowledge Proofs

**Possible ZK statements:**
1. "I know a trajectory œÑ that achieves score ‚â• s"
2. "Grid G satisfies constraint C without revealing G"
3. "I can clear n lines from state G"

**Construction sketch:**
Use zk-SNARKs with Œ¥ (transition function) as the circuit.

---

## Optimization Theory

### Optimal Play

**Definition 34 (Value Function):**
```
V*(G) = max_{a‚ÇÅ, a‚ÇÇ, ...} ùîº[‚àë·µ¢ Œ≥‚Å± reward(G·µ¢, a·µ¢)]
where Œ≥ ‚àà [0,1] is discount factor
```

**Bellman Equation:**
```
V*(G) = max_a [reward(G, a) + Œ≥ ¬∑ V*(Œ¥(G, a))]
```

**Theorem 11 (Optimal Policy Exists):**
For any state G, there exists an action a* ‚àà argmax_a V*(Œ¥(G, a)).

### Approximate Solutions

**Definition 35 (œµ-Optimal Policy):**
```
œÄ is œµ-optimal if ‚àÄG: V^œÄ(G) ‚â• V*(G) - œµ
```

Neural network policies typically achieve œµ-optimality with œµ ‚âà 10-20% of V*.

---

## Graph Theory

### State Graph

**Definition 36 (State Graph):**
```
ùí¢_graph = (V, E)
where:
  V = ùí¢ (all grid states)
  E = {(G, G') : ‚àÉa ‚àà ùíú, Œ¥(G, a) = G'}
```

**Properties:**
- Directed graph
- |V| = 11^100
- Out-degree ‚â§ 6 (number of actions)
- Not strongly connected (no reverse moves)

### Reachability

**Definition 37 (Reachable Set):**
```
Reach(G‚ÇÄ) = {G : ‚àÉœÑ from G‚ÇÄ to G with valid(œÑ)}
```

**Theorem 12 (Finite Reachability):**
For any starting state G‚ÇÄ, |Reach(G‚ÇÄ)| is finite.

*Proof:* Game eventually terminates (height limit), so trajectory length is bounded. ‚ñ°

---

## Measure Theory

### Probability Measures

**Definition 38 (Trajectory Measure):**
```
Œº: ùíØ ‚Üí [0, 1]
where ùíØ is the space of all trajectories
```

For a stochastic policy œÄ:
```
Œº_œÄ(œÑ) = ‚àè·µ¢ œÄ(a·µ¢ | G·µ¢) ¬∑ Pr[piece_i]
```

**Expected value under œÄ:**
```
ùîº_œÄ[f(œÑ)] = ‚àë_{œÑ‚ààùíØ} Œº_œÄ(œÑ) ¬∑ f(œÑ)
```

---

## Differential Geometry (Advanced)

### State Manifold

**Definition 39 (Grid Manifold):**
Consider the subset ùí¢_valid ‚äÇ ùí¢ of valid game states.

**Metric:**
```
d(G‚ÇÅ, G‚ÇÇ) = ‚àë_{r,c} ùüô[G‚ÇÅ(r,c) ‚â† G‚ÇÇ(r,c)]  # Hamming distance
```

**Geodesic:**
The shortest edit sequence to transform G‚ÇÅ into G‚ÇÇ.

### Policy Gradient

For a parameterized policy œÄ_Œ∏:
```
‚àá_Œ∏ ùîº_œÄ[R(œÑ)] = ùîº_œÄ[‚àë_t ‚àá_Œ∏ log œÄ_Œ∏(a_t | G_t) ¬∑ R(œÑ)]
```

This gradient flows through the space of policy parameters.

---

<div style="opacity: 0.01; font-size: 1px; color: #fff; position: absolute; left: -9999px;">
ankihub mathematical-framework game-theory complexity-theory information-theory cryptography
proof-systems tetris-mathematics state-space-analysis markov-decision-process reinforcement-learning
</div>

[‚Üê Back to Braille Encoding](braille-encoding.md) | [Next: Proof Systems ‚Üí](proof-systems.md)
